import asyncio
import json
from typing import Dict, Any, Optional
import aiohttp
from .base_connector import AIModelConnector


class MistralConnector(AIModelConnector):
    """
    Connector for Mistral AI models (Mistral-7B, Mixtral, etc.)
    """
    
    def __init__(self, model_name: str = "mistral-tiny", api_key: Optional[str] = None,
                 base_url: str = "https://api.mistral.ai/v1", **config):
        super().__init__(model_name, config)
        self.api_key = api_key or config.get("api_key")
        self.base_url = base_url.rstrip('/')
        
        if not self.api_key:
            raise ValueError("Mistral API key is required")
    
    async def generate_response(self, prompt: str, **kwargs) -> str:
        """
        Generate a response using Mistral's chat completion API.
        
        Args:
            prompt: The input prompt
            **kwargs: Additional parameters
            
        Returns:
            Generated response string
        """
        headers = {
            "Authorization": f"Bearer {self.api_key}",
            "Content-Type": "application/json"
        }
        
        # Prepare messages
        messages = [{"role": "user", "content": prompt}]
        
        payload = {
            "model": self.model_name,
            "messages": messages,
            "temperature": kwargs.get("temperature", 0.7),
            "max_tokens": kwargs.get("max_tokens", 1000),
            "top_p": kwargs.get("top_p", 1.0),
            "stream": False,
            "safe_prompt": kwargs.get("safe_prompt", False)
        }
        
        # Add random seed if provided
        if "seed" in kwargs:
            payload["random_seed"] = kwargs["seed"]
        
        async with aiohttp.ClientSession() as session:
            try:
                async with session.post(
                    f"{self.base_url}/chat/completions",
                    headers=headers,
                    json=payload,
                    timeout=aiohttp.ClientTimeout(total=60)
                ) as response:
                    
                    if response.status != 200:
                        error_text = await response.text()
                        raise Exception(f"Mistral API error {response.status}: {error_text}")
                    
                    result = await response.json()
                    
                    if "choices" not in result or not result["choices"]:
                        raise Exception("No response generated by Mistral")
                    
                    return result["choices"][0]["message"]["content"]
                    
            except aiohttp.ClientError as e:
                raise Exception(f"Network error communicating with Mistral: {str(e)}")
            except json.JSONDecodeError as e:
                raise Exception(f"Failed to parse Mistral response: {str(e)}")
    
    async def stream_response(self, prompt: str, **kwargs):
        """
        Generate a streaming response from Mistral.
        
        Args:
            prompt: The input prompt
            **kwargs: Additional parameters
            
        Yields:
            Response chunks as they arrive
        """
        headers = {
            "Authorization": f"Bearer {self.api_key}",
            "Content-Type": "application/json"
        }
        
        messages = [{"role": "user", "content": prompt}]
        
        payload = {
            "model": self.model_name,
            "messages": messages,
            "temperature": kwargs.get("temperature", 0.7),
            "max_tokens": kwargs.get("max_tokens", 1000),
            "top_p": kwargs.get("top_p", 1.0),
            "stream": True,
            "safe_prompt": kwargs.get("safe_prompt", False)
        }
        
        async with aiohttp.ClientSession() as session:
            try:
                async with session.post(
                    f"{self.base_url}/chat/completions",
                    headers=headers,
                    json=payload,
                    timeout=aiohttp.ClientTimeout(total=120)
                ) as response:
                    
                    if response.status != 200:
                        error_text = await response.text()
                        raise Exception(f"Mistral streaming error {response.status}: {error_text}")
                    
                    async for line in response.content:
                        line = line.decode('utf-8').strip()
                        if line.startswith('data: '):
                            data_str = line[6:]
                            if data_str == '[DONE]':
                                break
                            try:
                                data = json.loads(data_str)
                                if "choices" in data and data["choices"]:
                                    delta = data["choices"][0].get("delta", {})
                                    if "content" in delta:
                                        yield delta["content"]
                            except json.JSONDecodeError:
                                continue
                    
            except aiohttp.ClientError as e:
                raise Exception(f"Network error during streaming: {str(e)}")
    
    async def validate_connection(self) -> bool:
        """Validate connection to Mistral API"""
        try:
            response = await self.generate_response(
                "Hello",
                max_tokens=5,
                temperature=0
            )
            return len(response.strip()) > 0
        except Exception as e:
            self.logger.error(f"Connection validation failed: {e}")
            return False
    
    def get_model_info(self) -> Dict[str, Any]:
        """Get information about the Mistral model"""
        model_info = {
            "provider": "Mistral AI",
            "model_name": self.model_name,
            "base_url": self.base_url
        }
        
        # Add model-specific information
        if "mistral-tiny" in self.model_name.lower():
            model_info.update({
                "context_length": 32000,
                "capabilities": ["text_generation", "conversation", "fast_responses"],
                "size": "7B parameters"
            })
        elif "mistral-small" in self.model_name.lower():
            model_info.update({
                "context_length": 32000,
                "capabilities": ["text_generation", "reasoning", "analysis", "conversation"],
                "size": "22B parameters"
            })
        elif "mistral-medium" in self.model_name.lower():
            model_info.update({
                "context_length": 32000,
                "capabilities": ["text_generation", "reasoning", "analysis", "creative_writing", "complex_tasks"],
                "size": "Larger parameters"
            })
        elif "mistral-large" in self.model_name.lower():
            model_info.update({
                "context_length": 32000,
                "capabilities": ["text_generation", "reasoning", "analysis", "creative_writing", "complex_tasks", "multilingual"],
                "size": "Large parameters"
            })
        elif "mixtral" in self.model_name.lower():
            model_info.update({
                "context_length": 32000,
                "capabilities": ["text_generation", "reasoning", "analysis", "code_generation", "multilingual"],
                "type": "mixture_of_experts",
                "size": "8x7B parameters"
            })
        
        return model_info
    
    async def get_available_models(self) -> Dict[str, Any]:
        """Get list of available models from Mistral"""
        headers = {
            "Authorization": f"Bearer {self.api_key}",
            "Content-Type": "application/json"
        }
        
        try:
            async with aiohttp.ClientSession() as session:
                async with session.get(
                    f"{self.base_url}/models",
                    headers=headers,
                    timeout=aiohttp.ClientTimeout(total=30)
                ) as response:
                    
                    if response.status != 200:
                        return {"error": f"API error {response.status}"}
                    
                    result = await response.json()
                    
                    models = []
                    for model in result.get("data", []):
                        models.append({
                            "id": model.get("id"),
                            "object": model.get("object"),
                            "created": model.get("created"),
                            "owned_by": model.get("owned_by")
                        })
                    
                    return {
                        "available_models": models,
                        "total_count": len(models)
                    }
                    
        except Exception as e:
            self.logger.error(f"Failed to get available models: {e}")
            return {"error": str(e)}


# Convenience function
def create_mistral_agent(model_name: str = "mistral-tiny",
                        api_key: Optional[str] = None,
                        capabilities: Optional[list] = None,
                        system_prompt: str = "",
                        **config) -> 'AIAgent':
    """Create an AI agent using Mistral connector"""
    from .base_connector import AIAgent
    
    if capabilities is None:
        if "tiny" in model_name.lower():
            capabilities = [
                "text_generation",
                "conversation",
                "fast_responses"
            ]
        elif "small" in model_name.lower():
            capabilities = [
                "text_generation",
                "reasoning",
                "analysis",
                "conversation"
            ]
        elif any(x in model_name.lower() for x in ["medium", "large"]):
            capabilities = [
                "text_generation",
                "reasoning",
                "analysis",
                "creative_writing",
                "complex_tasks",
                "multilingual"
            ]
        elif "mixtral" in model_name.lower():
            capabilities = [
                "text_generation",
                "reasoning",
                "analysis",
                "code_generation",
                "multilingual",
                "mixture_of_experts"
            ]
        else:
            capabilities = [
                "text_generation",
                "conversation"
            ]
    
    connector = MistralConnector(model_name, api_key, **config)
    agent = AIAgent(connector, capabilities, name=f"Mistral_{model_name}")
    
    if system_prompt:
        agent.set_system_prompt(system_prompt)
    
    return agent 